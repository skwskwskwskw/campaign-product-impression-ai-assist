{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any, Union\n",
    "from datetime import date as date_type\n",
    "\n",
    "import clickhouse_connect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataclasses\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class AdMetric:\n",
    "    date: Union[str, date_type]\n",
    "    platform: str\n",
    "    campaignId: str\n",
    "    campaignName: str\n",
    "    adSetId: str\n",
    "    adSetName: str\n",
    "    adId: str\n",
    "    adName: str\n",
    "    spend: float\n",
    "    impressions: int\n",
    "    interactions: int\n",
    "    clicks: int\n",
    "    conversions: int\n",
    "    conversionValue: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AMAdStatus:\n",
    "    type: str\n",
    "    platform: str\n",
    "    campaignId: str\n",
    "    adSetId: str\n",
    "    adId: str\n",
    "    name: str\n",
    "    productType: str\n",
    "    budget: str\n",
    "    targetROAS: float\n",
    "    isActive: bool\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ClickHouse connection helper\n",
    "# ============================================================\n",
    "\n",
    "def connect_to_clickhouse():\n",
    "    return clickhouse_connect.get_client(host='localhost', port=8123, username='default')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Name resolution (latest names from fact_metrics)\n",
    "#   - safer keys include campaignId/adSetId to avoid collisions\n",
    "# ============================================================\n",
    "\n",
    "def _get_latest_names(website_id: str, market: str, client=None) -> Dict[str, str]:\n",
    "    if client is None:\n",
    "        client = connect_to_clickhouse()\n",
    "\n",
    "    where_market = \"AND market = {market: String}\" if market != 'all' else \"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH filtered_data AS (\n",
    "        SELECT\n",
    "            timestamp,\n",
    "            platform,\n",
    "            campaignId,\n",
    "            campaignName,\n",
    "            adSetId,\n",
    "            adSetName,\n",
    "            adId,\n",
    "            adName\n",
    "        FROM fact_metrics FINAL\n",
    "        WHERE websiteId = {{websiteId: String}}\n",
    "          {where_market}\n",
    "          AND isDelete = false\n",
    "    )\n",
    "    SELECT\n",
    "        'campaign' AS type,\n",
    "        platform,\n",
    "        campaignId,\n",
    "        '' AS adSetId,\n",
    "        '' AS adId,\n",
    "        argMaxIf(campaignName, timestamp, campaignName IS NOT NULL AND campaignName != '') AS name\n",
    "    FROM filtered_data\n",
    "    GROUP BY platform, campaignId\n",
    "    HAVING name != ''\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        'adSet' AS type,\n",
    "        platform,\n",
    "        campaignId,\n",
    "        adSetId,\n",
    "        '' AS adId,\n",
    "        argMaxIf(adSetName, timestamp, adSetName IS NOT NULL AND adSetName != '') AS name\n",
    "    FROM filtered_data\n",
    "    GROUP BY platform, campaignId, adSetId\n",
    "    HAVING name != ''\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        'ad' AS type,\n",
    "        platform,\n",
    "        campaignId,\n",
    "        adSetId,\n",
    "        adId,\n",
    "        argMaxIf(adName, timestamp, adName IS NOT NULL AND adName != '') AS name\n",
    "    FROM filtered_data\n",
    "    GROUP BY platform, campaignId, adSetId, adId\n",
    "    HAVING name != ''\n",
    "    \"\"\"\n",
    "\n",
    "    params = {'websiteId': website_id}\n",
    "    if market != 'all':\n",
    "        params['market'] = market\n",
    "\n",
    "    result = client.query(query, parameters=params)\n",
    "\n",
    "    # key format: type::platform::campaignId::adSetId::adId\n",
    "    return {f\"{row[0]}::{row[1]}::{row[2]}::{row[3]}::{row[4]}\": row[5] for row in result.result_rows}\n",
    "\n",
    "\n",
    "def _apply_latest_names_to_metrics(items: List[AdMetric], names_lookup: Dict[str, str]) -> None:\n",
    "    for item in items:\n",
    "        k_campaign = f\"campaign::{item.platform}::{item.campaignId}::::\"\n",
    "        if k_campaign in names_lookup:\n",
    "            item.campaignName = names_lookup[k_campaign]\n",
    "\n",
    "        k_adset = f\"adSet::{item.platform}::{item.campaignId}::{item.adSetId}::\"\n",
    "        if k_adset in names_lookup:\n",
    "            item.adSetName = names_lookup[k_adset]\n",
    "\n",
    "        k_ad = f\"ad::{item.platform}::{item.campaignId}::{item.adSetId}::{item.adId}\"\n",
    "        if k_ad in names_lookup:\n",
    "            item.adName = names_lookup[k_ad]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Ad-level metrics from fact_metrics\n",
    "# ============================================================\n",
    "\n",
    "def _get_ad_metrics(\n",
    "    website_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    timezone: str,\n",
    "    market: str,\n",
    "    client=None\n",
    ") -> List[AdMetric]:\n",
    "    if client is None:\n",
    "        client = connect_to_clickhouse()\n",
    "\n",
    "    where_market = \"AND market = {market: String}\" if market != 'all' else \"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "      toDate(timestamp, {{timezone: String}}) AS date,\n",
    "      platform,\n",
    "      campaignId,\n",
    "      adSetId,\n",
    "      adId,\n",
    "      sum(toFloat64(spend)) AS spend,\n",
    "      sum(impressions) AS impressions,\n",
    "      sum(interactions) AS interactions,\n",
    "      sum(clicks) AS clicks,\n",
    "      sum(conversions) AS conversions,\n",
    "      sum(toFloat64(conversionsValue)) AS conversionValue\n",
    "    FROM fact_metrics FINAL\n",
    "    WHERE\n",
    "      websiteId = {{websiteId: String}}\n",
    "      AND toDate(timestamp, {{timezone: String}}) >= toDate({{startDate: String}})\n",
    "      AND toDate(timestamp, {{timezone: String}}) <  toDate({{endDate: String}})\n",
    "      {where_market}\n",
    "      AND isDelete = false\n",
    "    GROUP BY date, platform, campaignId, adSetId, adId\n",
    "    ORDER BY date\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        'websiteId': website_id,\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "        'timezone': timezone,\n",
    "    }\n",
    "    if market != 'all':\n",
    "        params['market'] = market\n",
    "\n",
    "    result = client.query(query, parameters=params)\n",
    "\n",
    "    return [\n",
    "        AdMetric(\n",
    "            date=row[0],\n",
    "            platform=str(row[1]) if row[1] is not None else '',\n",
    "            campaignId=str(row[2]) if row[2] is not None else '',\n",
    "            campaignName='',\n",
    "            adSetId=str(row[3]) if row[3] is not None else '',\n",
    "            adSetName='',\n",
    "            adId=str(row[4]) if row[4] is not None else '',\n",
    "            adName='',\n",
    "            spend=float(row[5]) if row[5] is not None else 0.0,\n",
    "            impressions=int(row[6]) if row[6] is not None else 0,\n",
    "            interactions=int(row[7]) if row[7] is not None else 0,\n",
    "            clicks=int(row[8]) if row[8] is not None else 0,\n",
    "            conversions=int(row[9]) if row[9] is not None else 0,\n",
    "            conversionValue=float(row[10]) if row[10] is not None else 0.0,\n",
    "        )\n",
    "        for row in result.result_rows\n",
    "    ]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SKU-level contributions (sku_weight + sku_gross_profit + share)\n",
    "#   - FIXES:\n",
    "#     1) No alias in WHERE (JSONExtractString(track,'model') instead)\n",
    "#     2) Returns productId, productName, sku_weight (qty), share\n",
    "#     3) sku_spend/impressions computed from fact_metrics * share\n",
    "# ============================================================\n",
    "\n",
    "def _get_sku_contrib(\n",
    "    website_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    customer_type: str,\n",
    "    market: str,\n",
    "    timezone: str,\n",
    "    modelType: str = 'linear',\n",
    "    client=None,\n",
    ") -> pd.DataFrame:\n",
    "    if client is None:\n",
    "        client = connect_to_clickhouse()\n",
    "\n",
    "    where_parts = [\n",
    "        'o.websiteId = {websiteId: String}',\n",
    "        'toDate(o.orderedAt, {timezone: String}) >= toDate({startDate: String})',\n",
    "        'toDate(o.orderedAt, {timezone: String}) <  toDate({endDate: String})'\n",
    "    ]\n",
    "\n",
    "    if market != 'all':\n",
    "        where_parts.append('o.market = {market: String}')\n",
    "    if customer_type == 'return':\n",
    "        where_parts.append('o.customerFirstOrderedAt < toDateTime({startDate: String}, {timezone: String})')\n",
    "    elif customer_type == 'new':\n",
    "        where_parts.append('o.customerFirstOrderedAt >= toDateTime({startDate: String}, {timezone: String})')\n",
    "\n",
    "    where_clause = ' AND '.join(where_parts)\n",
    "    where_market_metrics = \"AND market = {market: String}\" if market != 'all' else \"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH\n",
    "    order_sku AS (\n",
    "        SELECT\n",
    "            websiteId,\n",
    "            orderId,\n",
    "            productId,\n",
    "            sum(orderProductQuantity) AS sku_qty,\n",
    "            sum(grossProfit) AS sku_grossProfit\n",
    "        FROM fact_order_products o FINAL\n",
    "        WHERE {where_clause}\n",
    "        GROUP BY websiteId, orderId, productId\n",
    "    ),\n",
    "\n",
    "    order_totals AS (\n",
    "        SELECT\n",
    "            o.websiteId AS websiteId,\n",
    "            o.orderId   AS orderId,\n",
    "            toDate(argMax(o.orderedAt, o.lastUpdatedAt), {{timezone: String}}) AS date,\n",
    "            argMax(o.eventTracksJSON, o.lastUpdatedAt) AS eventTracksJSON\n",
    "        FROM fact_order_intelligence o FINAL\n",
    "        WHERE {where_clause}\n",
    "        GROUP BY o.websiteId, o.orderId\n",
    "    ),\n",
    "\n",
    "    product_details AS (\n",
    "        SELECT DISTINCT\n",
    "            a.websiteId,\n",
    "            a.productId,\n",
    "            a.productGroupId,\n",
    "            a.name AS productName,\n",
    "            b.name AS productGroupName\n",
    "        FROM (\n",
    "            SELECT\n",
    "                websiteId,\n",
    "                productId,\n",
    "                productGroupId,\n",
    "                argMax(name, updatedAt) AS name\n",
    "            FROM raw_products_new FINAL\n",
    "            WHERE websiteId = {{websiteId: String}}\n",
    "            GROUP BY websiteId, productId, productGroupId\n",
    "        ) AS a\n",
    "        LEFT JOIN (\n",
    "            SELECT DISTINCT\n",
    "                websiteId,\n",
    "                productGroupId,\n",
    "                name\n",
    "            FROM raw_product_groups_new FINAL\n",
    "            WHERE websiteId = {{websiteId: String}}\n",
    "        ) AS b\n",
    "            ON a.websiteId = b.websiteId\n",
    "           AND a.productGroupId = b.productGroupId\n",
    "    ),\n",
    "\n",
    "    unwind_tracks AS (\n",
    "        SELECT\n",
    "            ot.websiteId AS websiteId,\n",
    "            ot.orderId   AS orderId,\n",
    "            ot.date      AS date,\n",
    "            JSONExtractString(track, 'platform')    AS platform,\n",
    "            JSONExtractString(track, 'campaignId')  AS campaignId,\n",
    "            JSONExtractString(track, 'adSetId')     AS adSetId,\n",
    "            JSONExtractString(track, 'adId')        AS adId,\n",
    "            toFloat64OrZero(JSONExtractString(track, 'weight')) AS weight\n",
    "        FROM order_totals ot\n",
    "        ARRAY JOIN JSONExtractArrayRaw(ot.eventTracksJSON) AS track\n",
    "        WHERE JSONExtractString(track, 'model') = {{modelType: String}}\n",
    "    ),\n",
    "\n",
    "    sku_contrib AS (\n",
    "        SELECT\n",
    "            t.websiteId as websiteId,\n",
    "            t.date as date,\n",
    "            t.platform as platform,\n",
    "            t.campaignId as campaignId,\n",
    "            t.adSetId as adSetId,\n",
    "            t.adId as adId,\n",
    "            s.productId as productId,\n",
    "            pd.productGroupId as productGroupId,\n",
    "            sum(s.sku_qty) AS sku_weight,\n",
    "            sum(s.sku_grossProfit * t.weight) AS sku_grossProfit\n",
    "        FROM unwind_tracks t\n",
    "        INNER JOIN order_sku s\n",
    "            ON s.websiteId = t.websiteId\n",
    "           AND s.orderId   = t.orderId\n",
    "        LEFT JOIN product_details pd\n",
    "            ON pd.websiteId = t.websiteId\n",
    "           AND pd.productId = s.productId\n",
    "        GROUP BY\n",
    "            websiteId, date, platform, campaignId, adSetId, adId, productId, productGroupId\n",
    "    ),\n",
    "\n",
    "    sku_share AS (\n",
    "        SELECT\n",
    "            websiteId,\n",
    "            date,\n",
    "            platform,\n",
    "            campaignId,\n",
    "            adSetId,\n",
    "            adId,\n",
    "            productId,\n",
    "            productGroupId,\n",
    "            sku_weight,\n",
    "            sku_grossProfit,\n",
    "            sku_weight\n",
    "              / NULLIF(\n",
    "                  sum(sku_weight) OVER (PARTITION BY date, platform, campaignId, adSetId, adId),\n",
    "                  0\n",
    "                ) AS share\n",
    "        FROM sku_contrib\n",
    "    ),\n",
    "\n",
    "    metrics AS (\n",
    "        SELECT\n",
    "            toDate(timestamp, {{timezone: String}}) AS date,\n",
    "            platform,\n",
    "            campaignId,\n",
    "            adSetId,\n",
    "            adId,\n",
    "            sum(toFloat64(spend)) AS spend,\n",
    "            sum(impressions) AS impressions, \n",
    "            sum(interactions) AS interactions,\n",
    "            sum(clicks) AS clicks\n",
    "        FROM fact_metrics FINAL\n",
    "        WHERE\n",
    "            websiteId = {{websiteId: String}}\n",
    "            AND toDate(timestamp, {{timezone: String}}) >= toDate({{startDate: String}})\n",
    "            AND toDate(timestamp, {{timezone: String}}) <  toDate({{endDate: String}})\n",
    "            {where_market_metrics}\n",
    "            AND isDelete = false\n",
    "        GROUP BY date, platform, campaignId, adSetId, adId\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        s.date as date,\n",
    "        s.platform as platform,\n",
    "        s.campaignId as campaignId,\n",
    "        s.adSetId  as adSetId,\n",
    "        s.adId as adId,\n",
    "\n",
    "        s.productId as productId,\n",
    "        s.productGroupId as productGroupId,\n",
    "\n",
    "        s.sku_weight as sku_weight,\n",
    "        s.share as share,\n",
    "\n",
    "        m.spend * s.share       AS sku_spend,\n",
    "        m.impressions * s.share AS sku_impressions,\n",
    "        m.clicks * s.share       AS sku_clicks,\n",
    "\n",
    "        s.sku_grossProfit       AS sku_grossProfit,\n",
    "\n",
    "        pd.productName as productName,\n",
    "        pd.productGroupName as productGroupName\n",
    "    FROM sku_share s\n",
    "    LEFT JOIN metrics m\n",
    "        ON m.date       = s.date\n",
    "       AND m.platform   = s.platform\n",
    "       AND m.campaignId = s.campaignId\n",
    "       AND m.adSetId    = s.adSetId\n",
    "       AND m.adId       = s.adId\n",
    "    LEFT JOIN product_details pd\n",
    "        ON pd.websiteId = {{websiteId: String}}\n",
    "       AND pd.productId = s.productId\n",
    "    SETTINGS final = 1\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        'websiteId': website_id,\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "        'timezone': timezone,\n",
    "        'modelType': modelType,\n",
    "    }\n",
    "    if market != 'all':\n",
    "        params['market'] = market\n",
    "\n",
    "    return client.query_df(query, parameters=params)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SKU sales (all orders, including “organic”) from fact_order_products\n",
    "# ============================================================\n",
    "\n",
    "def _get_sku_sales(\n",
    "    website_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    customer_type: str,\n",
    "    market: str,\n",
    "    timezone: str,\n",
    "    client=None,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    if client is None:\n",
    "        client = connect_to_clickhouse()\n",
    "\n",
    "    where_parts = [\n",
    "        'o.websiteId = {websiteId: String}',\n",
    "        'toDate(o.orderedAt, {timezone: String}) >= toDate({startDate: String})',\n",
    "        'toDate(o.orderedAt, {timezone: String}) <  toDate({endDate: String})'\n",
    "    ]\n",
    "\n",
    "    if market != 'all':\n",
    "        where_parts.append('o.market = {market: String}')\n",
    "    if customer_type == 'return':\n",
    "        where_parts.append('o.customerFirstOrderedAt < toDateTime({startDate: String}, {timezone: String})')\n",
    "    elif customer_type == 'new':\n",
    "        where_parts.append('o.customerFirstOrderedAt >= toDateTime({startDate: String}, {timezone: String})')\n",
    "\n",
    "    where_clause = ' AND '.join(where_parts)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "      toDate(o.orderedAt, {{timezone: String}}) AS date,\n",
    "      p.productId,\n",
    "      sum(p.grossSales)                  AS grossSales,\n",
    "      sum(p.productDiscounts)            AS productDiscounts,\n",
    "      sum(p.orderRefundTotalPreShipping) AS orderRefundTotalPreShipping,\n",
    "      sum(p.productRefundProportionated) AS productRefundProportionated,\n",
    "      sum(p.netSales)                    AS netSales,\n",
    "      sum(p.productPurchaseCost)         AS productPurchaseCost,\n",
    "      sum(p.refundProductPurchaseCost)   AS refundProductPurchaseCost,\n",
    "      sum(p.grossProfit)                 AS grossProfit,\n",
    "      sum(p.variableCost)                AS variableCost,\n",
    "      sum(p.trackCost)                   AS trackCost,\n",
    "      sum(p.trackCostByCPC)              AS trackCostByCPC,\n",
    "      sum(p.marginalContribution)        AS marginalContribution,\n",
    "      sum(p.marginalContributionByCPC)   AS marginalContributionByCPC,\n",
    "      sum(p.fixedCost)                   AS fixedCost,\n",
    "      sum(p.netProfit)                   AS netProfit,\n",
    "      sum(p.netProfitByCPC)              AS netProfitByCPC,\n",
    "      countDistinct(o.orderId)           AS ordersCount\n",
    "    FROM fact_order_intelligence o\n",
    "    INNER JOIN fact_order_products p\n",
    "      ON p.websiteId = o.websiteId\n",
    "     AND p.orderId   = o.orderId\n",
    "    WHERE {where_clause}\n",
    "    GROUP BY date, p.productId\n",
    "    SETTINGS final = 1\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        'websiteId': website_id,\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "        'timezone': timezone,\n",
    "    }\n",
    "    if market != 'all':\n",
    "        params['market'] = market\n",
    "\n",
    "    result = client.query(query, parameters=params)\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for row in result.result_rows:\n",
    "        rows.append({\n",
    "            'date': row[0],\n",
    "            'productId': str(row[1]) if row[1] is not None else '',\n",
    "            'grossSales': float(row[2]) if row[2] is not None else 0.0,\n",
    "            'productDiscounts': float(row[3]) if row[3] is not None else 0.0,\n",
    "            'orderRefundTotalPreShipping': float(row[4]) if row[4] is not None else 0.0,\n",
    "            'productRefundProportionated': float(row[5]) if row[5] is not None else 0.0,\n",
    "            'netSales': float(row[6]) if row[6] is not None else 0.0,\n",
    "            'productPurchaseCost': float(row[7]) if row[7] is not None else 0.0,\n",
    "            'refundProductPurchaseCost': float(row[8]) if row[8] is not None else 0.0,\n",
    "            'grossProfit': float(row[9]) if row[9] is not None else 0.0,\n",
    "            'variableCost': float(row[10]) if row[10] is not None else 0.0,\n",
    "            'trackCost': float(row[11]) if row[11] is not None else 0.0,\n",
    "            'trackCostByCPC': float(row[12]) if row[12] is not None else 0.0,\n",
    "            'marginalContribution': float(row[13]) if row[13] is not None else 0.0,\n",
    "            'marginalContributionByCPC': float(row[14]) if row[14] is not None else 0.0,\n",
    "            'fixedCost': float(row[15]) if row[15] is not None else 0.0,\n",
    "            'netProfit': float(row[16]) if row[16] is not None else 0.0,\n",
    "            'netProfitByCPC': float(row[17]) if row[17] is not None else 0.0,\n",
    "            'ordersCount': int(row[18]) if row[18] is not None else 0,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Klaviyo cost + ad status (kept as-is, minor tidy)\n",
    "# ============================================================\n",
    "\n",
    "def _get_klaviyo_cost(website_id: str, start_date: str, end_date: str, timezone: str, client=None) -> Optional[float]:\n",
    "    if client is None:\n",
    "        client = connect_to_clickhouse()\n",
    "\n",
    "    query = \"\"\"\n",
    "    WITH daily_spends AS (\n",
    "        SELECT\n",
    "          toDate(arrayJoin(\n",
    "            arrayMap(x -> startedAt + toIntervalDay(x), range(0, dateDiff('day', startedAt, endedAt)))\n",
    "          ), {timezone: String}) AS date,\n",
    "          ROUND(value / dateDiff('day', startedAt, endedAt), 4) AS spend\n",
    "        FROM raw_cost_metrics m FINAL\n",
    "        WHERE websiteId = {websiteId: String} AND code = 'klaviyo'\n",
    "          AND endedAt >= toDate({startDate: String}) AND startedAt <= toDate({endDate: String})\n",
    "    )\n",
    "    SELECT ROUND(SUM(spend), 2) AS spend\n",
    "    FROM daily_spends\n",
    "    WHERE date >= toDate({startDate: String}) AND date < toDate({endDate: String})\n",
    "    \"\"\"\n",
    "\n",
    "    result = client.query(query, parameters={\n",
    "        'websiteId': website_id,\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "        'timezone': timezone\n",
    "    })\n",
    "    rows = result.result_rows\n",
    "    return float(rows[0][0]) if rows and rows[0][0] is not None else None\n",
    "\n",
    "\n",
    "def _get_ad_status(\n",
    "    website_id: str,\n",
    "    campaign_search_strings: List[str],\n",
    "    klaviyo_search_strings: List[str],   # kept for parity even if unused\n",
    "    ad_set_search_strings: List[str],\n",
    "    ad_search_strings: List[str],\n",
    "    client=None\n",
    ") -> List[AMAdStatus]:\n",
    "    if client is None:\n",
    "        client = connect_to_clickhouse()\n",
    "\n",
    "    max_count = max(\n",
    "        len(campaign_search_strings),\n",
    "        len(klaviyo_search_strings),\n",
    "        len(ad_set_search_strings),\n",
    "        len(ad_search_strings),\n",
    "        1\n",
    "    )\n",
    "    batch_size = 1000\n",
    "    all_results: List[AMAdStatus] = []\n",
    "\n",
    "    for i in range(0, max_count, batch_size):\n",
    "        batch_campaigns = campaign_search_strings[i:i + batch_size] or ['']\n",
    "        batch_ad_sets = ad_set_search_strings[i:i + batch_size] or ['']\n",
    "        batch_ads = ad_search_strings[i:i + batch_size] or ['']\n",
    "\n",
    "        query = \"\"\"\n",
    "          WITH final_campaigns AS (\n",
    "            SELECT 'campaign' AS type, c.platform, c.campaignId, '' AS adSetId, '' AS adId,\n",
    "              argMax(c.name, c.insertedAt) AS name,\n",
    "              argMax(c.productType, c.insertedAt) AS productType,\n",
    "              argMax(CONCAT(c.budget, ' ', c.budgetPeriod), c.insertedAt) AS budget,\n",
    "              argMax(toString(c.targetROAS), c.insertedAt) AS targetROAS,\n",
    "              argMax(c.isActive, c.insertedAt) AS isActive\n",
    "            FROM raw_campaigns c\n",
    "            WHERE c.websiteId = {websiteId: String}\n",
    "              AND c.campaignId IN ({campaignSearchStrings: Array(String)})\n",
    "            GROUP BY c.websiteId, c.platform, c.campaignId\n",
    "          ),\n",
    "          final_ad_sets AS (\n",
    "            SELECT 'adSet' AS type, a.platform, a.campaignId, a.adSetId, '' AS adId,\n",
    "              argMax(a.name, a.insertedAt) AS name,\n",
    "              '' AS productType, '' AS budget, '' AS targetROAS,\n",
    "              argMax(a.isActive, a.insertedAt) AS isActive\n",
    "            FROM raw_ad_sets a\n",
    "            WHERE a.websiteId = {websiteId: String}\n",
    "              AND a.adSetId IN ({adSetSearchStrings: Array(String)})\n",
    "            GROUP BY a.websiteId, a.platform, a.campaignId, a.adSetId\n",
    "          ),\n",
    "          final_ads AS (\n",
    "            SELECT 'ad' AS type, a.platform, a.campaignId, a.adSetId, a.adId,\n",
    "              argMax(a.name, a.insertedAt) AS name,\n",
    "              '' AS productType, '' AS budget, '' AS targetROAS,\n",
    "              argMax(a.isActive, a.insertedAt) AS isActive\n",
    "            FROM raw_ads a\n",
    "            WHERE a.websiteId = {websiteId: String}\n",
    "              AND a.adId IN ({adSearchStrings: Array(String)})\n",
    "            GROUP BY a.websiteId, a.platform, a.campaignId, a.adSetId, a.adId\n",
    "          )\n",
    "          SELECT type, platform, campaignId, adSetId, adId, name, productType, budget, targetROAS, isActive\n",
    "          FROM (\n",
    "            SELECT * FROM final_campaigns\n",
    "            UNION ALL SELECT * FROM final_ad_sets\n",
    "            UNION ALL SELECT * FROM final_ads\n",
    "          )\n",
    "          SETTINGS final = 1\n",
    "        \"\"\"\n",
    "\n",
    "        result = client.query(query, parameters={\n",
    "            'websiteId': website_id,\n",
    "            'campaignSearchStrings': batch_campaigns,\n",
    "            'adSetSearchStrings': batch_ad_sets,\n",
    "            'adSearchStrings': batch_ads\n",
    "        })\n",
    "\n",
    "        for row in result.result_rows:\n",
    "            all_results.append(AMAdStatus(\n",
    "                type=row[0],\n",
    "                platform=row[1],\n",
    "                campaignId=str(row[2]) if row[2] is not None else '',\n",
    "                adSetId=str(row[3]) if row[3] is not None else '',\n",
    "                adId=str(row[4]) if row[4] is not None else '',\n",
    "                name=row[5] if row[5] is not None else '',\n",
    "                productType=row[6] if row[6] is not None else '',\n",
    "                budget=row[7] if row[7] is not None else '',\n",
    "                targetROAS=float(row[8]) if row[8] and row[8] != '' else 0.0,\n",
    "                isActive=bool(row[9])\n",
    "            ))\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main API handler\n",
    "# ============================================================\n",
    "\n",
    "def main_api_handler_sku_attr(\n",
    "    website_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    customer_type: str,\n",
    "    market: str,\n",
    "    timezone: str = 'UTC',\n",
    "    campaign_prod: Optional[pd.DataFrame] = None,\n",
    "    client=None\n",
    ") -> Dict[str, Any]:\n",
    "    if client is None:\n",
    "        client = connect_to_clickhouse()\n",
    "\n",
    "    # website timezone override\n",
    "    tz_df = client.query_df(\n",
    "        \"SELECT DISTINCT timezone FROM websites FINAL WHERE websiteId = {websiteId: String}\",\n",
    "        parameters={'websiteId': website_id}\n",
    "    )\n",
    "    if not tz_df.empty and tz_df.iloc[0].get('timezone'):\n",
    "        timezone = tz_df.iloc[0]['timezone']\n",
    "\n",
    "    # 1) ad metrics (totals)\n",
    "    ad_metrics = _get_ad_metrics(\n",
    "        website_id=website_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        timezone=timezone,\n",
    "        market=market,\n",
    "        client=client\n",
    "    )\n",
    "\n",
    "    names_lookup = _get_latest_names(website_id, market, client)\n",
    "    _apply_latest_names_to_metrics(ad_metrics, names_lookup)\n",
    "\n",
    "    df_ad = pd.DataFrame([{\n",
    "        'date': m.date,\n",
    "        'platform': m.platform,\n",
    "        'campaignId': str(m.campaignId),\n",
    "        'campaignName': m.campaignName,\n",
    "        'adSetId': str(m.adSetId),\n",
    "        'adSetName': m.adSetName,\n",
    "        'adId': str(m.adId),\n",
    "        'adName': m.adName,\n",
    "        'spend': m.spend,\n",
    "        'impressions': m.impressions,\n",
    "        'interactions': m.interactions,\n",
    "        'clicks': m.clicks,\n",
    "        'conversions': m.conversions,\n",
    "        'conversionValue': m.conversionValue,\n",
    "    } for m in ad_metrics])\n",
    "\n",
    "    if not df_ad.empty:\n",
    "        df_ad['date'] = pd.to_datetime(df_ad['date'])\n",
    "        for c in ['campaignId', 'adSetId', 'adId', 'platform']:\n",
    "            df_ad[c] = df_ad[c].astype(str)\n",
    "\n",
    "    # 2) sku contrib (weights + share + attributed gp by sku + fair spend/impressions)\n",
    "    df_alloc = _get_sku_contrib(\n",
    "        website_id=website_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        customer_type=customer_type,\n",
    "        market=market,\n",
    "        timezone=timezone,\n",
    "        client=client\n",
    "    )\n",
    "\n",
    "    if df_alloc is None or df_alloc.empty:\n",
    "        klaviyo_cost = _get_klaviyo_cost(website_id, start_date, end_date, timezone, client)\n",
    "        return {\n",
    "            'adData': df_ad,\n",
    "            'skuAllocation': pd.DataFrame(),\n",
    "            'skuPerformance': pd.DataFrame(),\n",
    "            'adStatus': pd.DataFrame(),\n",
    "            'klaviyoCost': klaviyo_cost,\n",
    "        }\n",
    "\n",
    "    # normalize dtypes\n",
    "    df_alloc['date'] = pd.to_datetime(df_alloc['date'])\n",
    "    for col in ['productId', 'productGroupId', 'campaignId', 'adSetId', 'adId', 'platform']:\n",
    "        if col in df_alloc.columns:\n",
    "            df_alloc[col] = df_alloc[col].astype(str)\n",
    "\n",
    "    # 3) join ad totals into allocation base (do NOT overwrite later)\n",
    "    if not df_ad.empty:\n",
    "        df_ad_for_join = df_ad[[\n",
    "            'date', 'platform', 'campaignId', 'adSetId', 'adId',\n",
    "            'spend', 'impressions', 'interactions', 'clicks', 'campaignName', 'adSetName', 'adName'\n",
    "        ]].rename(columns={\n",
    "            'spend': 'ad_spend_total',\n",
    "            'impressions': 'ad_impressions_total',\n",
    "            'interactions': 'ad_interactions_total',\n",
    "            'clicks': 'ad_clicks_total'\n",
    "        })\n",
    "\n",
    "        df_alloc = df_alloc.merge(\n",
    "            df_ad_for_join,\n",
    "            on=['date', 'platform', 'campaignId', 'adSetId', 'adId'],\n",
    "            how='left'\n",
    "        )\n",
    "    else:\n",
    "        df_alloc['ad_spend_total'] = 0.0\n",
    "        df_alloc['ad_impressions_total'] = 0.0\n",
    "        df_alloc['ad_interactions_total'] = 0.0\n",
    "        df_alloc['ad_clicks_total'] = 0.0\n",
    "        df_alloc['campaignName'] = ''\n",
    "        df_alloc['adSetName'] = ''\n",
    "        df_alloc['adName'] = ''\n",
    "\n",
    "    df_alloc['ad_spend_total'] = df_alloc['ad_spend_total'].fillna(0.0).astype(float)\n",
    "    df_alloc['ad_impressions_total'] = df_alloc['ad_impressions_total'].fillna(0.0).astype(float)\n",
    "    df_alloc['ad_interactions_total'] = df_alloc['ad_interactions_total'].fillna(0.0).astype(float)\n",
    "    df_alloc['ad_clicks_total'] = df_alloc['ad_clicks_total'].fillna(0.0).astype(float)\n",
    "\n",
    "    # 4) isLead tagging (optional)\n",
    "    if campaign_prod is not None and not campaign_prod.empty:\n",
    "        cp = campaign_prod.copy()\n",
    "        if 'productGroupIds' in cp.columns:\n",
    "            cp = cp.explode('productGroupIds').rename(columns={'productGroupIds': 'productGroupId'})\n",
    "\n",
    "        for col in ['productGroupId', 'campaignId', 'adSetId', 'adId']:\n",
    "            if col in cp.columns:\n",
    "                cp[col] = cp[col].astype(str)\n",
    "\n",
    "        cp['isLead'] = 1\n",
    "        cp = cp.drop_duplicates(subset=['campaignId', 'adSetId', 'adId', 'productGroupId'])\n",
    "\n",
    "        df_alloc = df_alloc.merge(\n",
    "            cp[['campaignId', 'adSetId', 'adId', 'productGroupId', 'isLead']],\n",
    "            on=['campaignId', 'adSetId', 'adId', 'productGroupId'],\n",
    "            how='left'\n",
    "        )\n",
    "        df_alloc['isLead'] = df_alloc['isLead'].fillna(0).astype(int)\n",
    "    else:\n",
    "        df_alloc['isLead'] = 0\n",
    "\n",
    "    # 5) compute weights + lead-only shares\n",
    "    group_keys = ['date', 'platform', 'campaignId', 'adSetId', 'adId']\n",
    "\n",
    "    df_alloc['sku_weight'] = pd.to_numeric(df_alloc['sku_weight'], errors='coerce').fillna(0.0)\n",
    "    df_alloc['share'] = pd.to_numeric(df_alloc['share'], errors='coerce').fillna(0.0)\n",
    "\n",
    "    df_alloc['total_weight_all'] = df_alloc.groupby(group_keys)['sku_weight'].transform('sum')\n",
    "    df_alloc['lead_weight'] = np.where(df_alloc['isLead'] == 1, df_alloc['sku_weight'], 0.0)\n",
    "    df_alloc['total_weight_lead'] = df_alloc.groupby(group_keys)['lead_weight'].transform('sum')\n",
    "\n",
    "    # Only compute gross profit total from attributed rows\n",
    "    df_alloc['ad_gross_profit_total'] = df_alloc.groupby(group_keys)['sku_grossProfit'].transform('sum')\n",
    "\n",
    "    df_alloc['share_lead_only'] = np.where(\n",
    "        df_alloc['total_weight_lead'] > 0,\n",
    "        df_alloc['lead_weight'] / df_alloc['total_weight_lead'],\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    # lead only (strict): allocate FULL ad totals only across lead SKUs if lead_weight exists\n",
    "    df_alloc['spend_lead_only'] = df_alloc['ad_spend_total'] * df_alloc['share_lead_only']\n",
    "    df_alloc['impressions_lead_only'] = df_alloc['ad_impressions_total'] * df_alloc['share_lead_only']\n",
    "    df_alloc['clicks_lead_only'] = df_alloc['ad_clicks_total'] * df_alloc['share_lead_only']\n",
    "    df_alloc['gross_profit_lead_only'] = df_alloc['ad_gross_profit_total'] * df_alloc['share_lead_only']\n",
    "\n",
    "    # 6) skuAllocation output (fair = already proportional in SQL)\n",
    "    keep_cols = [\n",
    "        'date',\n",
    "        'productId',\n",
    "        'productGroupId',\n",
    "        'productGroupName',\n",
    "        'productName',\n",
    "        'platform',\n",
    "        'campaignId',\n",
    "        'campaignName',\n",
    "        'adSetId',\n",
    "        'adSetName',\n",
    "        'adId',\n",
    "        'adName',\n",
    "        'isLead',\n",
    "        'sku_weight',\n",
    "        'share',\n",
    "        'sku_grossProfit',\n",
    "        'sku_spend',\n",
    "        'sku_impressions',\n",
    "        'sku_clicks',\n",
    "        'gross_profit_lead_only',\n",
    "        'spend_lead_only',\n",
    "        'impressions_lead_only',\n",
    "        'clicks_lead_only',\n",
    "    ]\n",
    "    for c in keep_cols:\n",
    "        if c not in df_alloc.columns:\n",
    "            df_alloc[c] = np.nan\n",
    "\n",
    "    df_sku_alloc = (\n",
    "        df_alloc[keep_cols]\n",
    "        .rename(columns={\n",
    "            'sku_grossProfit': 'gross_profit_fair',\n",
    "            'sku_spend': 'spend_fair',\n",
    "            'sku_impressions': 'impressions_fair',\n",
    "            'sku_clicks': 'clicks_fair',\n",
    "        })\n",
    "        .sort_values(['date', 'productId', 'platform', 'campaignId', 'adSetId', 'adId'])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # 7) put gross profit total on df_ad (ad-day level) from df_alloc, not from df_sku_alloc missing columns\n",
    "    if not df_ad.empty and not df_alloc.empty:\n",
    "        keys = ['date', 'platform', 'campaignId', 'adSetId', 'adId']\n",
    "        df_gp = (\n",
    "            df_alloc.groupby(keys, as_index=False)['sku_grossProfit']\n",
    "            .sum()\n",
    "            .rename(columns={'sku_grossProfit': 'ad_gross_profit'})\n",
    "        )\n",
    "        df_ad = df_ad.merge(df_gp, on=keys, how='left')\n",
    "        df_ad['ad_gross_profit'] = df_ad['ad_gross_profit'].fillna(0.0)\n",
    "\n",
    "    # 8) sku sales (organic + all)\n",
    "    sku_sales_rows = _get_sku_sales(\n",
    "        website_id=website_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        customer_type=customer_type,\n",
    "        market=market,\n",
    "        timezone=timezone,\n",
    "        client=client\n",
    "    )\n",
    "    df_sku_sales = pd.DataFrame(sku_sales_rows)\n",
    "    if not df_sku_sales.empty:\n",
    "        df_sku_sales['date'] = pd.to_datetime(df_sku_sales['date'])\n",
    "        df_sku_sales['productId'] = df_sku_sales['productId'].astype(str)\n",
    "\n",
    "    # 9) skuPerformance = sales + fair + lead-only\n",
    "    if not df_sku_sales.empty and not df_sku_alloc.empty:\n",
    "        agg = df_sku_alloc.groupby(['date', 'productId'], as_index=False).agg(\n",
    "            sku_spend_fair=('spend_fair', 'sum'),\n",
    "            sku_impressions_fair=('impressions_fair', 'sum'),\n",
    "            sku_gross_profit_fair=('gross_profit_fair', 'sum'),\n",
    "            sku_clicks_fair=('clicks_fair', 'sum'),\n",
    "\n",
    "            sku_spend_lead_only=('spend_lead_only', 'sum'),\n",
    "            sku_impressions_lead_only=('impressions_lead_only', 'sum'),\n",
    "            sku_gross_profit_lead_only=('gross_profit_lead_only', 'sum'),\n",
    "            sku_clicks_lead_only=('clicks_lead_only', 'sum'),\n",
    "        )\n",
    "\n",
    "        df_sku_perf = df_sku_sales.merge(agg, on=['date', 'productId'], how='left')\n",
    "\n",
    "        fill_cols = [c for c in agg.columns if c not in ('date', 'productId')]\n",
    "        for c in fill_cols:\n",
    "            df_sku_perf[c] = df_sku_perf[c].fillna(0.0)\n",
    "\n",
    "        # attach dims\n",
    "        dims = df_sku_alloc[['productId', 'productGroupId', 'productGroupName', 'productName']].drop_duplicates('productId')\n",
    "        df_sku_perf = df_sku_perf.merge(dims, on='productId', how='left')\n",
    "        df_sku_perf = df_sku_perf.sort_values(['date', 'productId']).reset_index(drop=True)\n",
    "    else:\n",
    "        df_sku_perf = pd.DataFrame()\n",
    "\n",
    "    # 10) ad status + klaviyo cost\n",
    "    campaign_ids = list({m.campaignId for m in ad_metrics if m.campaignId})\n",
    "    adset_ids = list({m.adSetId for m in ad_metrics if m.adSetId})\n",
    "    ad_ids = list({m.adId for m in ad_metrics if m.adId})\n",
    "\n",
    "    ad_status_rows = _get_ad_status(\n",
    "        website_id=website_id,\n",
    "        campaign_search_strings=[str(x) for x in campaign_ids],\n",
    "        klaviyo_search_strings=[],\n",
    "        ad_set_search_strings=[str(x) for x in adset_ids],\n",
    "        ad_search_strings=[str(x) for x in ad_ids],\n",
    "        client=client\n",
    "    )\n",
    "\n",
    "    df_ad_status = pd.DataFrame([{\n",
    "        'type': s.type,\n",
    "        'platform': s.platform,\n",
    "        'campaignId': s.campaignId,\n",
    "        'adSetId': s.adSetId,\n",
    "        'adId': s.adId,\n",
    "        'name': s.name,\n",
    "        'productType': s.productType,\n",
    "        'budget': s.budget,\n",
    "        'targetROAS': s.targetROAS,\n",
    "        'isActive': s.isActive,\n",
    "    } for s in ad_status_rows])\n",
    "\n",
    "    klaviyo_cost = _get_klaviyo_cost(website_id, start_date, end_date, timezone, client)\n",
    "\n",
    "    # return\n",
    "    if not df_ad.empty:\n",
    "        df_ad = df_ad.sort_values(['date', 'platform', 'campaignId', 'adSetId', 'adId']).reset_index(drop=True)\n",
    "\n",
    "    return {\n",
    "        'adData': df_ad,\n",
    "        'skuAllocation': df_sku_alloc,\n",
    "        'skuPerformance': df_sku_perf,\n",
    "        'adStatus': df_ad_status,\n",
    "        'klaviyoCost': klaviyo_cost,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ClickHouse utils with AWS Secrets (optional)\n",
    "# ============================================================\n",
    "from botocore.config import Config \n",
    "from botocore.exceptions import ClientError, ParamValidationError\n",
    "import boto3\n",
    "import json, joblib\n",
    "\n",
    "\n",
    "\n",
    "def initialize_credentials(\n",
    "    secret_name=\"SHARED_LAMBDA_CREDENTIALS\",\n",
    "    region_name=\"ap-southeast-2\",\n",
    "    timeout=15,\n",
    "    profile_name=\"default\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize the global credentials by calling get_secret_with_retry.\n",
    "    \"\"\"\n",
    "    global credentials\n",
    "    credentials = get_secret_with_retry(secret_name, region_name, timeout, profile_name)[0]\n",
    "    return credentials\n",
    "\n",
    "\n",
    "def get_secret_with_retry(\n",
    "    secret_name=\"SHARED_LAMBDA_CREDENTIALS\",\n",
    "    region_name=\"ap-southeast-2\",\n",
    "    timeout=15,\n",
    "    profile_name=\"default\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Retrieves a secret from AWS Secrets Manager with retry logic and a timeout.\n",
    "    \"\"\"\n",
    "    config = Config(connect_timeout=timeout, read_timeout=timeout)\n",
    "    try:\n",
    "        session = boto3.session.Session(profile_name=profile_name, region_name=region_name)\n",
    "        client = session.client(service_name='secretsmanager', region_name=region_name, config=config)\n",
    "\n",
    "        resp = client.get_secret_value(\n",
    "            SecretId=secret_name,\n",
    "            VersionStage='AWSCURRENT'\n",
    "        )\n",
    "        secret = resp['SecretString']\n",
    "        secret_dict = json.loads(secret)\n",
    "        return secret_dict, secret\n",
    "    except Exception:\n",
    "        # Fallback to default session (e.g. Lambda)\n",
    "        session = boto3.session.Session(region_name=region_name)\n",
    "        client = session.client(service_name='secretsmanager', region_name=region_name, config=config)\n",
    "        resp = client.get_secret_value(\n",
    "            SecretId=secret_name,\n",
    "            VersionStage='AWSCURRENT'\n",
    "        )\n",
    "        secret = resp['SecretString']\n",
    "        secret_dict = json.loads(secret)\n",
    "        return secret_dict, secret\n",
    "\n",
    "\n",
    "def create_clickhouse_client(credentials, database='profitpeak'):\n",
    "    \"\"\"\n",
    "    Create a ClickHouse client using credentials from Secrets Manager.\n",
    "    Handles vpce.* host rewriting as fallback.\n",
    "    \"\"\"\n",
    "    original_host = credentials['CLICKHOUSE_URL'].replace('https://', '')\n",
    "    port = int(credentials['CLICKHOUSE_PORT'])\n",
    "    user = credentials['CLICKHOUSE_USER']\n",
    "    password = credentials['CLICKHOUSE_PASSWORD']\n",
    "\n",
    "    try:\n",
    "        return clickhouse_connect.get_client(\n",
    "            host=original_host,\n",
    "            port=port,\n",
    "            secure=True,\n",
    "            username=user,\n",
    "            verify=False,\n",
    "            password=password,\n",
    "            database=database\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"First attempt failed with host='{original_host}': {e}\")\n",
    "        alternative_host = original_host.replace('vpce.', '')\n",
    "        if alternative_host != original_host:\n",
    "            print(f\"Trying again after removing 'vpce.': {alternative_host}\")\n",
    "            try:\n",
    "                return clickhouse_connect.get_client(\n",
    "                    host=alternative_host,\n",
    "                    port=port,\n",
    "                    secure=True,\n",
    "                    username=user,\n",
    "                    verify=False,\n",
    "                    password=password,\n",
    "                    database=database\n",
    "                )\n",
    "            except Exception as e2:\n",
    "                print(f\"Second attempt also failed with host='{alternative_host}': {e2}\")\n",
    "                raise\n",
    "        else:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = initialize_credentials(profile_name='live')\n",
    "client = create_clickhouse_client(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_prod = joblib.load('df_final_lead_prods_campaign.pkl')\n",
    "campaign_prod.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_credentials(profile_name='live')\n",
    "client = create_clickhouse_client(credentials)\n",
    "res = main_api_handler_sku_attr(website_id='6839260124a2adf314674a5e', start_date='2025-10-01', end_date='2025-12-01', customer_type='all', market = 'all', client=client, campaign_prod=campaign_prod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_id = '6839260124a2adf314674a5e'\n",
    "tz_df = client.query_df(\n",
    "    f\"SELECT DISTINCT timezone FROM websites FINAL WHERE websiteId = '{website_id}'\"\n",
    ")\n",
    "if not tz_df.empty and tz_df.iloc[0]['timezone']:\n",
    "    timezone = tz_df.iloc[0]['timezone']\n",
    "\n",
    "\n",
    "df_alloc = _get_sku_contrib(\n",
    "    website_id='6839260124a2adf314674a5e',\n",
    "    start_date='2025-10-01', end_date='2025-12-01', customer_type='all', market = 'all', \n",
    "    timezone=timezone,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "if campaign_prod is not None and not campaign_prod.empty:\n",
    "    cp = campaign_prod.copy()  \n",
    "    if 'productGroupIds' in cp.columns:\n",
    "        cp = cp.explode('productGroupIds').rename(columns={'productGroupIds': 'productGroupId'})\n",
    "    for col in ['productGroupId', 'campaignId', 'adSetId', 'adId']:\n",
    "        cp[col] = cp[col].astype(str)                 \n",
    "    cp['isLead'] = 1\n",
    "    cp = cp.drop_duplicates(subset=['campaignId', 'adSetId', 'adId', 'productGroupId'])\n",
    "\n",
    "    print(df_alloc.shape)\n",
    "    df_alloc = df_alloc.merge(\n",
    "        cp[['campaignId', 'adSetId', 'adId', 'productGroupId', 'isLead']],\n",
    "        on=['campaignId', 'adSetId', 'adId', 'productGroupId'],\n",
    "        how='left'\n",
    "    )\n",
    "    df_alloc['isLead'] = df_alloc['isLead'].fillna(0).astype(int)\n",
    "    print(df_alloc.shape)\n",
    "else:\n",
    "    df_alloc['isLead'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = res['skuAllocation']\n",
    "temp.fillna('', inplace=True)\n",
    "\n",
    "temp.to_csv('sku_allocation_v2.csv', index = False)\n",
    "# temp.head(20)\n",
    "# find duplicates with same date and productId\n",
    "# temp[temp.duplicated(subset=['date', 'productGroupId', 'campaignId', 'adSetId', 'adId', 'platform'], keep=False)][temp.platform == 'google']\n",
    "# temp[(temp.productGroupId == '7181358956607') & (temp.date == '2025-10-01\t') & (temp.adId == '659231372798')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('sku_allocation_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['campaignName', 'campaignId']][(temp.campaignName.isnull()) & (temp.platform == 'google')].drop_duplicates().campaignId.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['skuAllocation'][['gross_profit_fair', 'gross_profit_lead_only', 'spend_fair', 'spend_lead_only', \\\n",
    "                      'impressions_fair', 'impressions_lead_only', 'clicks_fair', 'clicks_lead_only']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[(temp.campaigId == '22472868880') & (temp.platform == 'google')][['campaignId', 'adSetId', 'adId', 'date']].\\\n",
    "    groupby(['campaignId', 'adSetId', 'adId'])['date'].agg('min').reset_index().sort_values('date', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### check the different in amount \n",
    "# temp1 = res['skuAllocation'].groupby(['date', 'platform'], observed= False)[['ad_spend', 'ad_gross_profit']].agg('sum').reset_index()\n",
    "# temp1 = temp1[temp1.ad_spend > 0]\n",
    "# temp2 = res['adData'].groupby(['date', 'platform'], observed= False)[['spend']].agg('sum').reset_index()\n",
    "\n",
    "# temp3 = temp1.merge(temp2, on= ['date', 'platform'], how= 'left')\n",
    "# temp3[np.abs(temp3.ad_spend - temp3.spend) > 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp = campaign_prod.copy()\n",
    "# if 'productGroupIds' in cp.columns:\n",
    "#     cp = cp.explode('productGroupIds')\n",
    "#     cp = cp.rename(columns={'productGroupIds': 'productGroupId'})\n",
    "\n",
    "# cp['productGroupId'] = cp['productGroupId'].astype(str)\n",
    "# print(\"campaign_prod duplicate keys:\", cp.duplicated(subset=[\"campaignId\",\"adSetId\",\"adId\",\"productGroupId\"]).sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uvpy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
